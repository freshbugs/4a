<!DOCTYPE html>
<html lang="en">
<head>
<meta  charset="UTF-8">
<title>Math 4A, Lecture 29</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>                
<link rel="stylesheet" type="text/css" href="my4a.css">
</head>
<body>

<h1>Review</h1>

<h2>Advertisement</h2>

<p>
The
<a href="https://ucsbdrp.weebly.com/">Directed Reading Program</a>
is a way to see some more advanced mathematics.
</p>

<h2>Missing the word "span"</h2>

<p>
Let $A = \begin{bmatrix} -6&12\\-3&6 \end{bmatrix}$.
The statement
$$ \operatorname{col} A
   = \left\{ \begin{bmatrix} -6\\-3 \end{bmatrix} \right\}$$
is <span class=red>FALSE</span>
because it is missing the word "span".
</p>

<h2>Roots of polynomials</h2>

<p>
The characteristic polynomial of an $n \times n$ matrix
is a degree $n$ polynomial.
It has $n$ roots,
if you count multiplicities and allow complex roots.
These are the eigenvalues.
</p>

<p>
<span class=red>Example:</span>
$\lambda^4 + \lambda^3 - 12\lambda$.
</p>

<p>
Obviously
$$\lambda^4 + \lambda^3 - 12\lambda
  = \lambda(\lambda^3 + \lambda^2 - 12)$$
</p>

<p>
Now factor $\lambda^3 + \lambda^2 - 12$.
</p>

<p>
If there is an integer root then it is a factor of $12$.
Try $\pm 1$, $\pm 2$, $\pm 3$, $\pm 4$, $\pm 6$, $\pm 12$.
It turns out $2$ is a root.
</p>

<p>
Factor by long division, or guess and check.
$$\lambda^3 + \lambda^2 - 12
  = (\lambda - 2)(\star\lambda^2 + \star\lambda + \star)?$$
$$\lambda^3 + \lambda^2 - 12
  = (\lambda - 2)(\lambda^2 + 3\lambda + 6).$$
</p>

<p>
$\lambda^2 + 3\lambda + 6$ has no real roots,
by the quadratic formula or completing the square.
$$
\begin{align}
\lambda^2 + 3\lambda + 6
&= \lambda^2 + 3\lambda + \left(\frac{3}{2}\right)^2 + \frac{15}{4} \\
&= \left(\lambda + \frac{3}{2}\right)^2 + \frac{15}{4} \\
&\gt 0
\end{align}
$$
</p>


<h2>Question 1</h2>

<p>
Find reduced row echelon form of:
</p>

<h3>(a)</h3>

<p>
$$\begin{bmatrix} 1&0\\0&0\\0&2 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0\\0&2\\0&0 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0\\0&1\\0&0 \end{bmatrix}$$
Check: the two columns are linearly independent,
so reduced echelon form is the first two columns of an identity matrix.
</p>

<h3>(b)</h3>

<p>
$$\begin{bmatrix} 0&1&2\\1&2&3 \end{bmatrix}
\leadsto \begin{bmatrix} 1&2&3\\0&1&2 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0&-1\\0&1&2 \end{bmatrix}$$
Check: the first two columns are linearly independent,
and the third is two times the second minus the first.
</p>

<h3>(c)</h3>

<p>
$$\begin{bmatrix} 2&1&0\\3&2&1 \end{bmatrix}
\leadsto \begin{bmatrix} 2&1&0\\1&1&1 \end{bmatrix}
\leadsto \begin{bmatrix} 1&1&1\\2&1&0 \end{bmatrix}$$
$$\leadsto \begin{bmatrix} 1&1&1\\0&-1&-2 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0&-1\\0&-1&-2 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0&-1\\0&1&2 \end{bmatrix}$$
Check: the first two columns are linearly independent,
and the third is two times the second minus the first.
</p>

<h2>Question 2</h2>

<p>
Is $\begin{bmatrix} 0\\2\\3 \end{bmatrix}$
in the span of
$\left\{
\begin{bmatrix} 1\\3\\6 \end{bmatrix},
\begin{bmatrix} 2\\4\\9 \end{bmatrix} \right\}$?
</p>

<p>
$\begin{bmatrix} 0\\2\\3 \end{bmatrix}
= 2 \begin{bmatrix} 1\\3\\6 \end{bmatrix}
- \begin{bmatrix} 2\\4\\9 \end{bmatrix}$,
so
<span class=red>yes</span>.
</p>

<h2>Question 3</h2>

<p>
Suppose reduced echelon form of $A$ is
$\begin{bmatrix} 1&2&0 \\ 0&0&1 \\ 0&0&0 \end{bmatrix}$.
</p>

<h3>(a)</h3>

<p>
How many solutions to $A \mathbf{x} = \mathbf{0}$?
</p>

<p>
The second column has no pivot.
It is a free variable in the solution to $[A | \mathbf{0}]$.
So there are
<span class=red>infinitely many solutions</span>.
</p>

<h3>(b)</h3>

<p>
Does $A \mathbf{x} = \mathbf{b}$ always have a solution?
</p>

<p>
Reduced echelon form has a row of zeros.
For some (almost every) $\mathbf{b}$,
the reduced echelon form of $[A | \mathbf{b}]$
has a pivot on the right of the line.
So
<span class=red>no</span>.
</p>

<h2>Question 4</h2>

<p>
Let $T \colon \mathbb{R}^2 \to \mathbb{R}^2$ be
$T \begin{bmatrix} x\\y \end{bmatrix} = \begin{bmatrix} y\\x \end{bmatrix}$.
Is $T$ one-to-one? onto?
</p>

<p class=green>
This question relates to &sect;1.9,
which we did not cover.
This year,
I would have to explain some terms.
</p>

<p>
Note that $T(\mathbf{x}) = A \mathbf{x}$
where $A = \begin{bmatrix} 0&1\\1&0 \end{bmatrix}$.
</p>

<p>
One-to-one means
$A \mathbf{x} = \mathbf{b}$ always has at most one solution.
(Maybe zero, maybe one, never infinity.)
</p>

<p>
Onto means
$A \mathbf{x} = \mathbf{b}$ always has at least one solution.
(Maybe infinity, maybe one, never zero.)
</p>

<h3>(a)</h3>

<p>
Is it one-to-one?
</p>

<p>
Reduced echelon form of $A$ has a pivot in every column,
so
<span class=red>yes</span>.
</p>

<h3>(b)</h3>

<p>
Is it onto?
</p>

<p>
Reduced echelon form of $A$ has a pivot in every row,
so
<span class=red>yes</span>.
</p>

<h2>Question 5</h2>

<p>
Let $A = \begin{bmatrix} 1&2\\0&3 \end{bmatrix}$.
Compute:
</p>

<ul>
<li>
$AA^T = 
\begin{bmatrix} 1&2\\0&3 \end{bmatrix}
\begin{bmatrix} 1&0\\2&3 \end{bmatrix}
= \begin{bmatrix} 5&6\\6&9 \end{bmatrix}$
</li>

<li>
$\det A = (1)(3) - (2)(0) = 3$
</li>

<li>
$A^{-1} = \displaystyle{\frac{1}{3}}
\begin{bmatrix} 3&-2\\0&1 \end{bmatrix}$
</li>
</ul>

<p>Checks:</p>

<ul>
<li> $(AA^T)^T = AA^T$. ($AA^T$ is "symmetric".) </li>
<li> $A$ is upper triangular,
     so its determinant is the product of the diagonal entries. </li>
<li> $\begin{bmatrix} 1&2\\0&3 \end{bmatrix}
     \begin{bmatrix} 3&-2\\0&1 \end{bmatrix} = 3I$.  </li>
</ul>

<h2>Question 6</h2>

<p>
Find a basis for the column space of
$\begin{bmatrix} 1&0&1 \\ 0&1&1 \\ 1&1&2 \end{bmatrix}$.
</p>

<p>
Row reduce.
$$\begin{bmatrix} 1&0&1 \\ 0&1&1 \\ 1&1&2 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0&1 \\ 0&1&1 \\ 0&1&1 \end{bmatrix}
\leadsto \begin{bmatrix} 1&0&1 \\ 0&1&1 \\ 0&0&0 \end{bmatrix}$$
Reduced echelon form has pivots in the first and second columns.
So the first and second columns of $A$ form a basis for the column space.
$$\left\{
\begin{bmatrix}1\\0\\1 \end{bmatrix},
\begin{bmatrix}0\\1\\1 \end{bmatrix}
\right\}$$
</p>

<p>
Check:
The column space is the span of the columns.
The third column is the sum of the other two,
so it is not needed.
The first two columns are linearly independent,
so they form a basis.
</p>

<h2>Question 7</h2>

<p>
Find a basis for the null space of
$\begin{bmatrix} 1&1&1\\0&0&0 \end{bmatrix}$.
</p>

<p>
It is already in reduced echelon form.
There is one pivot, and two free variables.
</p>

<p>
Solution to the homogeneous system of equations:
$$\begin{align}
x &= -y - z \\
y &= y \\
z &= z
\end{align}$$
</p>

<p>
As a vector equation:
$$
\begin{bmatrix} x \\ y \\ z \end{bmatrix}
= y \begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix}
  + z \begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix}$$
</p>

<p>
$\operatorname{Nul} A
= \operatorname{Span}
\left\{
\begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix},
\begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix} \right\}$.
</p>

<p>
$\operatorname{Nul} A$ has basis
$\left\{
\begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix},
\begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix} \right\}$.
</p>

<p>
Check:
these are linearly independent,
and in
$\operatorname{Nul} \begin{bmatrix} 1&1&1\\0&0&0 \end{bmatrix}$.
</p>

<h2>Question 8</h2>

<p>
Let $\mathcal{B} =
\left\{
\begin{bmatrix}1\\-1 \end{bmatrix},
\begin{bmatrix}1\\1 \end{bmatrix}
\right\}$
and $\mathbf{v} = \begin{bmatrix} 1\\0 \end{bmatrix}$.
Compute $[ \mathbf{v} ]_\mathcal{B}$.
</p>

<p>
$$\mathbf{v}
= \frac{1}{2} \begin{bmatrix} 1\\-1 \end{bmatrix}
+ \frac{1}{2} \begin{bmatrix} 1\\1 \end{bmatrix}$$
so
$[ \mathbf{v} ]_\mathcal{B} = \begin{bmatrix} 1/2 \\ 1/2 \end{bmatrix}$.
</p>

<h2>Question 9</h2>

<p>
Is $1$ an eigenvalue of
$\begin{bmatrix} 2&1&1 \\ 1&2&1 \\ 1&1&2 \end{bmatrix}$?
</p>

<p>
$\begin{bmatrix} 2&1&1 \\ 1&2&1 \\ 1&1&2 \end{bmatrix}
\begin{bmatrix} 1\\-1\\0 \end{bmatrix}
= \begin{bmatrix} 1\\-1\\0 \end{bmatrix}$,
so
<span class=red>yes</span>.
</p>

<h2>Question 10</h2>

<p>
Is
$\begin{bmatrix} 0&0&0 \\ -1&1&0 \\ 0&0&1 \end{bmatrix}$
diagonalizable?
</p>

<p>
The matrix is lower triangular,
so its eigenvalues are the diagonal entries:
$0$ with multiplicity $1$,
and $1$ with multiplicity $2$.
</p>

<p>
Note that:
$$\begin{bmatrix} 0&0&0 \\ -1&1&0 \\ 0&0&1 \end{bmatrix}
\begin{bmatrix} 0\\1\\0 \end{bmatrix}
= \begin{bmatrix} 0\\1\\0 \end{bmatrix}
\text{ and }
\begin{bmatrix} 0&0&0 \\ -1&1&0 \\ 0&0&1 \end{bmatrix}
\begin{bmatrix} 0\\0\\1 \end{bmatrix}
= \begin{bmatrix} 0\\0\\1 \end{bmatrix}
$$
so
$\begin{bmatrix}0\\1\\0\end{bmatrix}$
and
$\begin{bmatrix}0\\0\\1\end{bmatrix}$
are eigenvectors with eigenvalue $1$.
They are linearly independent
because they are not multiples of each other.
</p>

<p>
<span class=red>Yes</span>, $A$ is diagonalizable.
The columns of $P$ would be
two linearly independent eigenvectors with eigenvalue $1$,
and one eigenvector with eigenvalue $0$.
</p>

<p>
One possible diagonalization is:
$$
\begin{bmatrix} 0&0&0 \\ -1&1&0 \\ 0&0&1 \end{bmatrix}
= \begin{bmatrix} 1&0&0 \\ 1&1&0 \\ 0&0&1 \end{bmatrix}
\begin{bmatrix} 0&0&0 \\ 0&1&0 \\ 0&0&1 \end{bmatrix}
\begin{bmatrix} 1&0&0 \\ 1&1&0 \\ 0&0&1 \end{bmatrix}^{-1}$$
</p>

<p>
Multiply and check.
</p>

<h2>Question 11</h2>

<p>
Find the orthogonal projection
of $\begin{bmatrix} 1\\2\\0 \end{bmatrix}$
onto the span of
$\left\{
\begin{bmatrix} 1\\0\\0 \end{bmatrix},
\begin{bmatrix} 0\\1\\1 \end{bmatrix}
\right\}$.
</p>

<p class=green>
This question relates to &sect;6.8,
which we did not cover.
This year,
I would have to give a hint:
Try to write the vector as a linear combination,
and find a least squares solution.
</p>

<p>
If it were in the span (which it is not),
we could solve
$$
\begin{bmatrix} 1&0 \\ 0&1 \\ 0&1 \end{bmatrix}
\begin{bmatrix} x\\y \end{bmatrix}
= \begin{bmatrix} 1\\2\\0 \end{bmatrix}
$$
</p>

<p>
To find a least squares solution, solve:
$$
\begin{align}
  \begin{bmatrix} 1&0&0 \\ 0&1&1 \end{bmatrix}
  \begin{bmatrix} 1&0 \\ 0&1 \\ 0&1 \end{bmatrix}
  \begin{bmatrix} x\\y \end{bmatrix}
  &= \begin{bmatrix} 1&0&0 \\ 0&1&1 \end{bmatrix}
  \begin{bmatrix} 1\\2\\0 \end{bmatrix}
\\
  \begin{bmatrix} 1&0 \\ 0&2 \end{bmatrix}
  \begin{bmatrix} x\\y \end{bmatrix}
  &= \begin{bmatrix} 1\\2 \end{bmatrix}
\\
  \begin{bmatrix} x\\y \end{bmatrix}
  &= \begin{bmatrix} 1\\1 \end{bmatrix}
\end{align}
$$
</p>

<p>
So the orthogonal projection is
$$
\begin{bmatrix} 1&0 \\ 0&1 \\ 0&1 \end{bmatrix}
\begin{bmatrix} 1\\1 \end{bmatrix}
= \begin{bmatrix} 1\\1\\1 \end{bmatrix}
$$
</p>

<p>
Check:
$$\begin{bmatrix} 1\\2\\0 \end{bmatrix}
= \begin{bmatrix} 1\\1\\1 \end{bmatrix}
+ \begin{bmatrix} 0\\1\\-1 \end{bmatrix}$$
and
$\begin{bmatrix} 0\\1\\-1 \end{bmatrix}$
is orthogonal to both of the vectors in
$\left\{
\begin{bmatrix} 1\\0\\0 \end{bmatrix},
\begin{bmatrix} 0\\1\\1 \end{bmatrix}
\right\}$.
</p>

<h2>Question 12</h2>

<p>
Suppose $A$ is a $2 \times 4$ matrix with rank $2$.
</p>

<p>
Remember, $2 \times 4$ means
$$A = \begin{bmatrix}
\cdot&\cdot&\cdot&\cdot \\ \cdot&\cdot&\cdot&\cdot
\end{bmatrix}$$
</p>

<h3>(a)</h3>

<p>
What is $\dim \operatorname{Nul} A$?
</p>

<p>
The rank plus the nullity is the number of columns,
so
<span class=red> the nullity is $2$</span>.
</p>

<h3>(b)</h3>

<p>
Do the columns of $A$ span $\mathbb{R}^2$?
</p>

<p>
The columns of $A$ span the column space of $A$.
The dimension of the column space is the rank.
So the columns span a two-dimensional subspace of $\mathbb{R}^2$.
</p>

<p>
<span class=red>Yes</span>,
the columns of $A$ span $\mathbb{R}^2$.
</p>


</body>
</html>
